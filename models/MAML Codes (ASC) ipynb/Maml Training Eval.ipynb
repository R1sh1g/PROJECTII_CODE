{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16b7609c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80929ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.10.0-cp312-cp312-win_amd64.whl.metadata (31 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.20.3-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\python312\\lib\\site-packages (from torch) (4.13.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Downloading fsspec-2026.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from torch) (78.1.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.10.0-cp312-cp312-win_amd64.whl (113.8 MB)\n",
      "   ---------------------------------------- 0.0/113.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/113.8 MB 7.7 MB/s eta 0:00:15\n",
      "   ---------------------------------------- 0.6/113.8 MB 7.0 MB/s eta 0:00:17\n",
      "   ---------------------------------------- 0.8/113.8 MB 6.4 MB/s eta 0:00:18\n",
      "   ---------------------------------------- 1.1/113.8 MB 6.1 MB/s eta 0:00:19\n",
      "   ---------------------------------------- 1.3/113.8 MB 5.8 MB/s eta 0:00:20\n",
      "    --------------------------------------- 1.5/113.8 MB 5.9 MB/s eta 0:00:20\n",
      "    --------------------------------------- 1.7/113.8 MB 5.8 MB/s eta 0:00:20\n",
      "    --------------------------------------- 2.0/113.8 MB 5.5 MB/s eta 0:00:21\n",
      "    --------------------------------------- 2.2/113.8 MB 5.4 MB/s eta 0:00:21\n",
      "    --------------------------------------- 2.4/113.8 MB 5.5 MB/s eta 0:00:21\n",
      "    --------------------------------------- 2.7/113.8 MB 5.4 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 3.0/113.8 MB 5.7 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 3.5/113.8 MB 6.0 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 3.7/113.8 MB 5.8 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 4.0/113.8 MB 5.9 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 4.2/113.8 MB 5.9 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 4.5/113.8 MB 5.8 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 4.7/113.8 MB 5.8 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 5.0/113.8 MB 5.8 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 5.3/113.8 MB 5.8 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 5.8/113.8 MB 6.1 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 6.0/113.8 MB 6.1 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 6.1/113.8 MB 5.9 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.4/113.8 MB 5.9 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 7.0/113.8 MB 6.1 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 7.2/113.8 MB 6.1 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 7.6/113.8 MB 6.2 MB/s eta 0:00:17\n",
      "   -- ------------------------------------- 7.9/113.8 MB 6.2 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 8.3/113.8 MB 6.2 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 8.7/113.8 MB 6.3 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 9.1/113.8 MB 6.5 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 9.7/113.8 MB 6.6 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 10.0/113.8 MB 6.7 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 10.6/113.8 MB 6.8 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 11.0/113.8 MB 6.9 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 11.5/113.8 MB 7.2 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 11.7/113.8 MB 7.1 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 12.0/113.8 MB 7.2 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 12.3/113.8 MB 7.3 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 12.7/113.8 MB 7.4 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 13.1/113.8 MB 7.5 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 13.6/113.8 MB 7.6 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 14.1/113.8 MB 7.9 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 14.5/113.8 MB 8.1 MB/s eta 0:00:13\n",
      "   ----- ---------------------------------- 15.3/113.8 MB 8.6 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 15.9/113.8 MB 8.7 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 16.7/113.8 MB 9.6 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 17.4/113.8 MB 9.9 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 18.1/113.8 MB 10.6 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 18.7/113.8 MB 11.1 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 19.6/113.8 MB 11.5 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 20.5/113.8 MB 12.1 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 21.4/113.8 MB 12.8 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 22.0/113.8 MB 13.6 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 22.9/113.8 MB 14.9 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 23.6/113.8 MB 15.6 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 24.4/113.8 MB 16.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 25.1/113.8 MB 16.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 26.0/113.8 MB 17.2 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 26.8/113.8 MB 16.8 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 27.6/113.8 MB 17.3 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 28.7/113.8 MB 18.2 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 29.6/113.8 MB 18.2 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 30.6/113.8 MB 18.2 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 31.5/113.8 MB 18.2 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 32.5/113.8 MB 18.7 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 33.1/113.8 MB 18.2 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 33.8/113.8 MB 18.7 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 34.6/113.8 MB 18.2 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 35.4/113.8 MB 18.7 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 36.4/113.8 MB 18.7 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 37.3/113.8 MB 19.3 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 38.1/113.8 MB 19.3 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 39.1/113.8 MB 18.7 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 39.9/113.8 MB 19.3 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 41.0/113.8 MB 18.7 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 41.9/113.8 MB 18.7 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 42.5/113.8 MB 18.2 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 43.4/113.8 MB 18.7 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 43.9/113.8 MB 18.2 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 44.5/113.8 MB 17.7 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 45.1/113.8 MB 17.2 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 45.4/113.8 MB 16.8 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 45.8/113.8 MB 16.0 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 46.0/113.8 MB 15.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 46.3/113.8 MB 14.6 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 46.5/113.8 MB 13.9 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 46.7/113.8 MB 13.1 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 46.9/113.8 MB 12.6 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 47.0/113.8 MB 12.4 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 47.7/113.8 MB 12.1 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 48.2/113.8 MB 11.7 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 48.6/113.8 MB 11.3 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 49.0/113.8 MB 10.9 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 49.5/113.8 MB 10.7 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 49.7/113.8 MB 10.4 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 50.0/113.8 MB 10.1 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 50.6/113.8 MB 9.8 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 51.0/113.8 MB 9.6 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 51.8/113.8 MB 9.5 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 52.6/113.8 MB 9.5 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 53.4/113.8 MB 9.6 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 54.2/113.8 MB 9.8 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 55.1/113.8 MB 9.9 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 55.9/113.8 MB 10.7 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 56.7/113.8 MB 11.7 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 57.5/113.8 MB 13.6 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 58.3/113.8 MB 13.6 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 59.2/113.8 MB 14.9 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 60.0/113.8 MB 15.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 60.7/113.8 MB 16.8 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 61.3/113.8 MB 17.2 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 62.0/113.8 MB 17.2 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 62.5/113.8 MB 16.8 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 63.1/113.8 MB 16.4 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 63.7/113.8 MB 16.0 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 64.2/113.8 MB 15.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 64.9/113.8 MB 15.6 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 65.5/113.8 MB 15.6 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 66.1/113.8 MB 14.9 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 66.9/113.8 MB 14.9 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 67.5/113.8 MB 14.6 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 68.2/113.8 MB 14.6 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 68.9/113.8 MB 14.6 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 69.4/113.8 MB 13.6 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 69.8/113.8 MB 13.6 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 70.2/113.8 MB 13.4 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 70.6/113.8 MB 13.1 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 71.1/113.8 MB 12.6 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 71.4/113.8 MB 12.6 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 71.9/113.8 MB 12.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 72.6/113.8 MB 12.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 73.2/113.8 MB 12.1 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 73.9/113.8 MB 12.4 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 74.5/113.8 MB 12.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 74.9/113.8 MB 12.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 75.5/113.8 MB 12.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 76.0/113.8 MB 11.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 76.5/113.8 MB 11.7 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 77.0/113.8 MB 11.5 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 77.3/113.8 MB 11.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 77.8/113.8 MB 11.3 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 78.1/113.8 MB 10.9 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 78.3/113.8 MB 10.4 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 78.7/113.8 MB 10.2 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 79.1/113.8 MB 9.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 79.6/113.8 MB 10.1 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 80.3/113.8 MB 10.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 81.0/113.8 MB 10.6 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 81.7/113.8 MB 11.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 82.3/113.8 MB 11.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 82.8/113.8 MB 10.9 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 83.2/113.8 MB 10.9 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 83.6/113.8 MB 10.7 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 84.0/113.8 MB 10.4 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 84.4/113.8 MB 10.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 84.7/113.8 MB 10.1 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 85.0/113.8 MB 9.9 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 85.4/113.8 MB 9.8 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 85.8/113.8 MB 9.8 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 86.3/113.8 MB 9.6 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 86.8/113.8 MB 9.8 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 87.6/113.8 MB 10.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 88.3/113.8 MB 10.7 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 89.1/113.8 MB 11.5 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 89.6/113.8 MB 11.5 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 90.3/113.8 MB 11.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 91.1/113.8 MB 11.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 91.9/113.8 MB 11.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 92.6/113.8 MB 11.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 93.4/113.8 MB 12.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 94.2/113.8 MB 13.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 95.0/113.8 MB 14.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 95.6/113.8 MB 14.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 96.2/113.8 MB 15.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 97.1/113.8 MB 16.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 97.9/113.8 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 98.7/113.8 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 99.3/113.8 MB 16.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 100.2/113.8 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 101.0/113.8 MB 16.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 102.0/113.8 MB 16.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 102.8/113.8 MB 16.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 103.5/113.8 MB 16.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 104.5/113.8 MB 16.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 105.3/113.8 MB 17.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 106.2/113.8 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 107.0/113.8 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 107.8/113.8 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 108.7/113.8 MB 17.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 109.7/113.8 MB 18.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 110.5/113.8 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  111.4/113.8 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  112.3/113.8 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.2/113.8 MB 18.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.8/113.8 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.8/113.8 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.8/113.8 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  113.8/113.8 MB 18.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 113.8/113.8 MB 14.2 MB/s eta 0:00:00\n",
      "Downloading fsspec-2026.2.0-py3-none-any.whl (202 kB)\n",
      "   ---------------------------------------- 0.0/202.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 202.5/202.5 kB 12.8 MB/s eta 0:00:00\n",
      "Downloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.7/2.1 MB 23.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.4/2.1 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 16.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 14.7 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.9/6.3 MB 18.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.8/6.3 MB 19.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.8/6.3 MB 20.0 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 3.6/6.3 MB 18.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.3 MB 19.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.3 MB 18.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.1/6.3 MB 18.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 17.5 MB/s eta 0:00:00\n",
      "Downloading filelock-3.20.3-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 17.0 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, networkx, jinja2, fsspec, filelock, torch\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [Errno 13] Permission denied: 'c:\\\\Python312\\\\share\\\\man\\\\man1\\\\isympy.1'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13d0dd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\python312\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: pandas in c:\\python312\\lib\\site-packages (2.2.3)\n",
      "Collecting transformers\n",
      "  Downloading transformers-5.1.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ------- -------------------------------- 10.2/57.7 kB ? eta -:--:--\n",
      "     --------------------- ------------------ 30.7/57.7 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 57.7/57.7 kB 504.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: scikit-learn in c:\\python312\\lib\\site-packages (1.6.1)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas) (2025.2)\n",
      "Collecting huggingface-hub<2.0,>=1.3.0 (from transformers)\n",
      "  Downloading huggingface_hub-1.4.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from transformers) (24.2)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Downloading pyyaml-6.0.3-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2026.1.15-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.5/41.5 kB 1.0 MB/s eta 0:00:00\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typer-slim (from transformers)\n",
      "  Downloading typer_slim-0.21.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\rishi\\appdata\\roaming\\python\\python312\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\python312\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\python312\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from datasets) (3.20.3)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-23.0.0-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\python312\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Collecting httpx<1.0.0 (from datasets)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.6.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets)\n",
      "  Downloading multiprocess-0.70.18-py312-none-any.whl.metadata (7.5 kB)\n",
      "Collecting fsspec<=2025.10.0,>=2023.1.0 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.13.3-cp312-cp312-win_amd64.whl.metadata (8.4 kB)\n",
      "Collecting anyio (from httpx<1.0.0->datasets)\n",
      "  Using cached anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: certifi in c:\\python312\\lib\\site-packages (from httpx<1.0.0->datasets) (2025.1.31)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0->datasets)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in c:\\python312\\lib\\site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting shellingham (from huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\python312\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.13.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Collecting click>=8.0.0 (from typer-slim->transformers)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.8.0-cp312-cp312-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.7.1-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.4.1-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.22.0-cp312-cp312-win_amd64.whl.metadata (77 kB)\n",
      "     ---------------------------------------- 0.0/77.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 77.6/77.6 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading transformers-5.1.0-py3-none-any.whl (10.3 MB)\n",
      "   ---------------------------------------- 0.0/10.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/10.3 MB 4.3 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.4/10.3 MB 4.5 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.5/10.3 MB 4.7 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.6/10.3 MB 3.5 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.7/10.3 MB 3.1 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.9/10.3 MB 3.3 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.0/10.3 MB 3.1 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.3/10.3 MB 3.5 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.3/10.3 MB 3.3 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.5/10.3 MB 3.3 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.6/10.3 MB 3.2 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.6/10.3 MB 3.2 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.8/10.3 MB 3.0 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.9/10.3 MB 3.0 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.2/10.3 MB 3.1 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.3/10.3 MB 3.2 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.5/10.3 MB 3.3 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 2.7/10.3 MB 3.3 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 3.0/10.3 MB 3.4 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 3.2/10.3 MB 3.5 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.4/10.3 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.7/10.3 MB 3.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.9/10.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.2/10.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.2/10.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.4/10.3 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.6/10.3 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.7/10.3 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.9/10.3 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.1/10.3 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.2/10.3 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 5.3/10.3 MB 3.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.4/10.3 MB 3.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.5/10.3 MB 3.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.7/10.3 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.8/10.3 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.0/10.3 MB 3.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.1/10.3 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.2/10.3 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.3/10.3 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.5/10.3 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.8/10.3 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.9/10.3 MB 3.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.1/10.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.2/10.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.4/10.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.5/10.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.7/10.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.8/10.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.0/10.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.2/10.3 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.3/10.3 MB 3.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.5/10.3 MB 3.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.7/10.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.8/10.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.0/10.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.1/10.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.3/10.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.5/10.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.6/10.3 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.7/10.3 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.7/10.3 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.8/10.3 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.9/10.3 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.3 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.3/10.3 MB 3.3 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.3-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.4 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 71.7/78.4 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 78.4/78.4 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading datasets-4.5.0-py3-none-any.whl (515 kB)\n",
      "   ---------------------------------------- 0.0/515.2 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 174.1/515.2 kB 5.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 358.4/515.2 kB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  512.0/515.2 kB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 515.2/515.2 kB 3.6 MB/s eta 0:00:00\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "   ---------------------------------------- 0.0/84.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 84.1/84.1 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "   ---------------------------------------- 0.0/119.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 119.7/119.7 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "   ---------------------------------------- 0.0/201.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 201.0/201.0 kB 4.1 MB/s eta 0:00:00\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading huggingface_hub-1.4.1-py3-none-any.whl (553 kB)\n",
      "   ---------------------------------------- 0.0/553.3 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 286.7/553.3 kB 8.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 450.6/553.3 kB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 553.3/553.3 kB 5.0 MB/s eta 0:00:00\n",
      "Downloading multiprocess-0.70.18-py312-none-any.whl (150 kB)\n",
      "   ---------------------------------------- 0.0/150.3 kB ? eta -:--:--\n",
      "   -------------------------------------- - 143.4/150.3 kB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 150.3/150.3 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading pyarrow-23.0.0-cp312-cp312-win_amd64.whl (27.7 MB)\n",
      "   ---------------------------------------- 0.0/27.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/27.7 MB 4.8 MB/s eta 0:00:06\n",
      "    --------------------------------------- 0.6/27.7 MB 6.1 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.7/27.7 MB 5.9 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.8/27.7 MB 4.2 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.8/27.7 MB 4.2 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.8/27.7 MB 4.2 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.8/27.7 MB 4.2 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.9/27.7 MB 2.4 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 1.0/27.7 MB 2.3 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 1.1/27.7 MB 2.2 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 1.2/27.7 MB 2.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 1.5/27.7 MB 2.6 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.6/27.7 MB 2.8 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.8/27.7 MB 2.7 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.8/27.7 MB 2.7 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 1.8/27.7 MB 2.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 1.9/27.7 MB 2.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 1.9/27.7 MB 2.3 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.9/27.7 MB 2.3 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 2.0/27.7 MB 2.2 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 2.0/27.7 MB 2.1 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 2.0/27.7 MB 2.1 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 2.1/27.7 MB 1.9 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 2.1/27.7 MB 1.9 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 2.2/27.7 MB 1.9 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 2.3/27.7 MB 1.9 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 2.4/27.7 MB 1.9 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 2.5/27.7 MB 1.9 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 2.7/27.7 MB 2.0 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 2.8/27.7 MB 2.0 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 2.9/27.7 MB 2.0 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 3.0/27.7 MB 2.0 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 3.1/27.7 MB 2.1 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 3.3/27.7 MB 2.1 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 3.5/27.7 MB 2.1 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 3.6/27.7 MB 2.2 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 3.7/27.7 MB 2.2 MB/s eta 0:00:12\n",
      "   ----- ---------------------------------- 3.9/27.7 MB 2.2 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 4.1/27.7 MB 2.3 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 4.1/27.7 MB 2.3 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 4.2/27.7 MB 2.2 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 4.3/27.7 MB 2.2 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 4.4/27.7 MB 2.2 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 4.6/27.7 MB 2.3 MB/s eta 0:00:11\n",
      "   ------ --------------------------------- 4.8/27.7 MB 2.3 MB/s eta 0:00:11\n",
      "   ------- -------------------------------- 4.9/27.7 MB 2.3 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 5.0/27.7 MB 2.3 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 5.2/27.7 MB 2.3 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 5.4/27.7 MB 2.4 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 5.7/27.7 MB 2.4 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 5.8/27.7 MB 2.5 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 6.1/27.7 MB 2.5 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 6.1/27.7 MB 2.5 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 6.2/27.7 MB 2.5 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 6.5/27.7 MB 2.5 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 6.7/27.7 MB 2.6 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 6.8/27.7 MB 2.6 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 7.1/27.7 MB 2.6 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 7.4/27.7 MB 2.7 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 7.6/27.7 MB 2.7 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 7.9/27.7 MB 2.8 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 7.9/27.7 MB 2.8 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 8.2/27.7 MB 2.8 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 8.3/27.7 MB 2.8 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 8.5/27.7 MB 2.8 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 8.7/27.7 MB 2.9 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 8.9/27.7 MB 2.9 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 8.9/27.7 MB 2.8 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 9.0/27.7 MB 2.8 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 9.1/27.7 MB 2.8 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 9.1/27.7 MB 2.8 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 9.3/27.7 MB 2.8 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 9.5/27.7 MB 2.8 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 9.6/27.7 MB 2.8 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 9.8/27.7 MB 2.8 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 9.9/27.7 MB 2.8 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 10.1/27.7 MB 2.8 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 10.3/27.7 MB 2.8 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 10.4/27.7 MB 2.8 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 10.5/27.7 MB 2.8 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 10.6/27.7 MB 2.8 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 10.8/27.7 MB 2.8 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 10.9/27.7 MB 2.8 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 11.0/27.7 MB 2.8 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 11.0/27.7 MB 2.8 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 11.1/27.7 MB 2.8 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 11.2/27.7 MB 2.9 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 11.4/27.7 MB 2.9 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 11.7/27.7 MB 2.9 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 11.8/27.7 MB 2.9 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 12.0/27.7 MB 2.9 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 12.2/27.7 MB 3.2 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 12.5/27.7 MB 3.3 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 12.6/27.7 MB 3.3 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 12.8/27.7 MB 3.3 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 13.0/27.7 MB 3.3 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 13.2/27.7 MB 3.4 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 13.3/27.7 MB 3.4 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 13.5/27.7 MB 3.4 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 13.8/27.7 MB 3.4 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 14.0/27.7 MB 3.5 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 14.3/27.7 MB 3.5 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 14.5/27.7 MB 3.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 14.8/27.7 MB 3.7 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 15.1/27.7 MB 3.7 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 15.3/27.7 MB 3.8 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 15.7/27.7 MB 3.8 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 15.8/27.7 MB 3.8 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 16.1/27.7 MB 3.8 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 16.3/27.7 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 16.7/27.7 MB 4.0 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 16.8/27.7 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 16.9/27.7 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 16.9/27.7 MB 3.9 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 17.0/27.7 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 17.0/27.7 MB 3.8 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 17.1/27.7 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 17.2/27.7 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 17.4/27.7 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 17.8/27.7 MB 3.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 18.0/27.7 MB 3.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 18.2/27.7 MB 3.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 18.7/27.7 MB 3.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 19.0/27.7 MB 3.8 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 19.4/27.7 MB 4.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 19.7/27.7 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 20.1/27.7 MB 4.3 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 20.4/27.7 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 20.8/27.7 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 21.1/27.7 MB 4.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 21.4/27.7 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 21.7/27.7 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 21.7/27.7 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 22.0/27.7 MB 5.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 22.3/27.7 MB 5.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 22.6/27.7 MB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 22.8/27.7 MB 5.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 23.1/27.7 MB 5.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 23.3/27.7 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 23.6/27.7 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 23.8/27.7 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 24.1/27.7 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 24.4/27.7 MB 5.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 24.7/27.7 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 25.1/27.7 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 25.3/27.7 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 25.7/27.7 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 26.0/27.7 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 26.2/27.7 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 26.6/27.7 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 26.9/27.7 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.2/27.7 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.6/27.7 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.7/27.7 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 27.7/27.7 MB 6.3 MB/s eta 0:00:00\n",
      "Downloading pyyaml-6.0.3-cp312-cp312-win_amd64.whl (154 kB)\n",
      "   ---------------------------------------- 0.0/154.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 154.0/154.0 kB 9.0 MB/s eta 0:00:00\n",
      "Downloading regex-2026.1.15-cp312-cp312-win_amd64.whl (277 kB)\n",
      "   ---------------------------------------- 0.0/277.2 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 256.0/277.2 kB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 277.2/277.2 kB 4.2 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "   ---------------------------------------- 0.0/341.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 341.4/341.4 kB 10.7 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.22.2-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.4/2.7 MB 8.7 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.7/2.7 MB 7.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.1/2.7 MB 9.0 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.5/2.7 MB 7.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.8/2.7 MB 7.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.2/2.7 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.5/2.7 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading typer_slim-0.21.1-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/47.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/47.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 47.4/47.4 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.6.0-cp312-cp312-win_amd64.whl (31 kB)\n",
      "Downloading aiohttp-3.13.3-cp312-cp312-win_amd64.whl (455 kB)\n",
      "   ---------------------------------------- 0.0/455.4 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 215.0/455.4 kB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 455.4/455.4 kB 5.7 MB/s eta 0:00:00\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "   ---------------------------------------- 0.0/108.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 108.3/108.3 kB 6.5 MB/s eta 0:00:00\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.4/2.9 MB 8.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.7/2.9 MB 7.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 0.9/2.9 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.2/2.9 MB 6.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.5/2.9 MB 6.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.7/2.9 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.1/2.9 MB 6.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.4/2.9 MB 6.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.7/2.9 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 6.4 MB/s eta 0:00:00\n",
      "Using cached anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading frozenlist-1.8.0-cp312-cp312-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.6/44.6 kB ? eta 0:00:00\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading multidict-6.7.1-cp312-cp312-win_amd64.whl (46 kB)\n",
      "   ---------------------------------------- 0.0/46.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.1/46.1 kB ? eta 0:00:00\n",
      "Downloading propcache-0.4.1-cp312-cp312-win_amd64.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/41.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 41.7/41.7 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading yarl-1.22.0-cp312-cp312-win_amd64.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 87.2/87.2 kB 4.8 MB/s eta 0:00:00\n",
      "Installing collected packages: xxhash, tqdm, shellingham, safetensors, regex, pyyaml, pyarrow, propcache, multidict, hf-xet, h11, fsspec, frozenlist, dill, click, attrs, anyio, aiohappyeyeballs, yarl, typer-slim, multiprocess, httpcore, aiosignal, httpx, aiohttp, huggingface-hub, tokenizers, datasets, transformers, evaluate\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to write executable - trying to use .deleteme logic\n",
      "ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'c:\\\\Python312\\\\Scripts\\\\tqdm.exe' -> 'c:\\\\Python312\\\\Scripts\\\\tqdm.exe.deleteme'\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy pandas transformers tqdm scikit-learn datasets evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48cc8fd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e819055",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModel\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 2  Imports\n",
    "# ============================\n",
    "\n",
    "import os\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from collections import defaultdict, OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdefa928",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ============================\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Cell 3  Seed + Device\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# ============================\u001b[39;00m\n\u001b[32m      4\u001b[39m SEED = \u001b[32m42\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mrandom\u001b[49m.seed(SEED)\n\u001b[32m      6\u001b[39m np.random.seed(SEED)\n\u001b[32m      7\u001b[39m torch.manual_seed(SEED)\n",
      "\u001b[31mNameError\u001b[39m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 3  Seed + Device\n",
    "# ============================\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba59b81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint dir: /content/drive/MyDrive/Capstone Project/outputs_maml\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 4  Config\n",
    "# ============================\n",
    "@dataclass\n",
    "class CFG:\n",
    "    # Data\n",
    "    train_csv: str = r\"trainmaml.csv\"  # change if needed\n",
    "    test_csv: str  = r\"testmaml.csv\"   # change if needed\n",
    "\n",
    "    # Model\n",
    "    model_name: str = \"roberta-base\"\n",
    "    max_len: int = 128\n",
    "    num_labels: int = 3\n",
    "\n",
    "    # Labels\n",
    "    sentiment_map: dict = None\n",
    "    id2label: dict = None\n",
    "\n",
    "    # Episodes\n",
    "    n_way: int = 3\n",
    "    k_shot: int = 4\n",
    "    q_query: int = 2\n",
    "\n",
    "    # MAML\n",
    "    inner_lr: float = 1e-2\n",
    "    inner_steps: int = 3\n",
    "\n",
    "    meta_lr: float = 2e-5\n",
    "    tasks_per_meta_batch: int = 4\n",
    "\n",
    "    epochs: int = 4\n",
    "    meta_iters_per_epoch: int = 200\n",
    "\n",
    "    # Eval\n",
    "    eval_episodes: int = 200\n",
    "\n",
    "    # Output\n",
    "    ckpt_dir: str = r\"/Users/Rishi/PROJECTII_CODE/models\"\n",
    "\n",
    "cfg = CFG(\n",
    "    sentiment_map={\"negative\": 0, \"neutral\": 1, \"positive\": 2},\n",
    "    id2label={0: \"negative\", 1: \"neutral\", 2: \"positive\"},\n",
    ")\n",
    "\n",
    "os.makedirs(cfg.ckpt_dir, exist_ok=True)\n",
    "print(\"Checkpoint dir:\", cfg.ckpt_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "499aea8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (7090, 3)\n",
      "Test shape : (901, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7130ad11-7c86-4afa-b5f9-5d7a6bf91923\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>aspect</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It might be the best sit down food I've had in...</td>\n",
       "      <td>food</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It might be the best sit down food I've had in...</td>\n",
       "      <td>place</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hostess was extremely accommodating when we ar...</td>\n",
       "      <td>staff</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7130ad11-7c86-4afa-b5f9-5d7a6bf91923')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-7130ad11-7c86-4afa-b5f9-5d7a6bf91923 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-7130ad11-7c86-4afa-b5f9-5d7a6bf91923');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                            sentence aspect sentiment\n",
       "0  It might be the best sit down food I've had in...   food  positive\n",
       "1  It might be the best sit down food I've had in...  place   neutral\n",
       "2  Hostess was extremely accommodating when we ar...  staff  positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 5  Load data\n",
    "# ============================\n",
    "train_df = pd.read_csv(cfg.train_csv)\n",
    "test_df = pd.read_csv(cfg.test_csv)\n",
    "\n",
    "req_cols = {\"sentence\", \"aspect\", \"sentiment\"}\n",
    "assert req_cols.issubset(set(train_df.columns)), f\"Train missing columns. Found: {train_df.columns}\"\n",
    "assert req_cols.issubset(set(test_df.columns)), f\"Test missing columns. Found: {test_df.columns}\"\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape :\", test_df.shape)\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef6a6648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible train aspects: 8\n",
      "Eligible test aspects : 6\n",
      "Sample train aspects: ['ambience', 'food', 'menu', 'miscellaneous', 'place', 'price', 'service', 'staff']\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 6  Index builder\n",
    "# ============================\n",
    "\n",
    "def build_index(df: pd.DataFrame):\n",
    "    idx = defaultdict(lambda: defaultdict(list))\n",
    "    for _, r in df.iterrows():\n",
    "        sent = str(r[\"sentence\"])\n",
    "        asp = str(r[\"aspect\"])\n",
    "        pol = str(r[\"sentiment\"]).strip().lower()\n",
    "        if pol not in cfg.sentiment_map:\n",
    "            continue\n",
    "        y = int(cfg.sentiment_map[pol])\n",
    "        idx[asp][y].append((sent, asp, y))\n",
    "    return idx\n",
    "\n",
    "\n",
    "def valid_aspects(idx) -> list:\n",
    "    need = cfg.k_shot + cfg.q_query\n",
    "    val = []\n",
    "    for asp, bylab in idx.items():\n",
    "        ok = True\n",
    "        for c in range(cfg.n_way):\n",
    "            if len(bylab.get(c, [])) < need:\n",
    "                ok = False\n",
    "                break\n",
    "        if ok:\n",
    "            val.append(asp)\n",
    "    return sorted(val)\n",
    "\n",
    "train_index = build_index(train_df)\n",
    "test_index = build_index(test_df)\n",
    "\n",
    "train_aspects = valid_aspects(train_index)\n",
    "test_aspects = valid_aspects(test_index)\n",
    "\n",
    "print(\"Eligible train aspects:\", len(train_aspects))\n",
    "print(\"Eligible test aspects :\", len(test_aspects))\n",
    "print(\"Sample train aspects:\", train_aspects[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09897384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 7  Sample episode\n",
    "# ============================\n",
    "\n",
    "def sample_episode(idx, aspect: str):\n",
    "    support, query = [], []\n",
    "    for c in range(cfg.n_way):\n",
    "        pool = idx[aspect][c]\n",
    "        # shuffle copy\n",
    "        pool = pool.copy()\n",
    "        random.shuffle(pool)\n",
    "        support.extend(pool[: cfg.k_shot])\n",
    "        query.extend(pool[cfg.k_shot : cfg.k_shot + cfg.q_query])\n",
    "    random.shuffle(support)\n",
    "    random.shuffle(query)\n",
    "    return support, query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bef21162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f3f3438b81431f9516567d637953b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d2fd8c5d774783ba9e9ead08ffaf6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619da0c20a354bd5a0601abf6d6732bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125a15cb5e694cdc9994f204404f6238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b360f56867554938b59d1aa16ef77005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 8  Tokenizer + encode\n",
    "# ============================\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(cfg.model_name)\n",
    "\n",
    "\n",
    "def encode_batch(examples):\n",
    "    sents = [x[0] for x in examples]\n",
    "    asps = [x[1] for x in examples]\n",
    "    ys = torch.tensor([x[2] for x in examples], dtype=torch.long, device=device)\n",
    "\n",
    "    enc = tok(\n",
    "        sents,\n",
    "        asps,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=cfg.max_len,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = enc[\"input_ids\"].to(device)\n",
    "    attention_mask = enc[\"attention_mask\"].to(device)\n",
    "    return input_ids, attention_mask, ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e7979a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51053c6bd066404b88d0fac1f6769207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baec689f76e54508be88695344ede73e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/197 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RobertaModel LOAD REPORT from: roberta-base\n",
      "Key                             | Status     | \n",
      "--------------------------------+------------+-\n",
      "lm_head.layer_norm.bias         | UNEXPECTED | \n",
      "lm_head.dense.weight            | UNEXPECTED | \n",
      "lm_head.bias                    | UNEXPECTED | \n",
      "lm_head.dense.bias              | UNEXPECTED | \n",
      "roberta.embeddings.position_ids | UNEXPECTED | \n",
      "lm_head.layer_norm.weight       | UNEXPECTED | \n",
      "pooler.dense.bias               | MISSING    | \n",
      "pooler.dense.weight             | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACSCTransformer\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 9  Model\n",
    "# ============================\n",
    "class ACSCTransformer(nn.Module):\n",
    "    def __init__(self, model_name: str, num_labels: int):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        hidden = self.encoder.config.hidden_size\n",
    "        self.classifier = nn.Linear(hidden, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls = out.last_hidden_state[:, 0]  # [B, H]\n",
    "        logits = self.classifier(cls)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = ACSCTransformer(cfg.model_name, cfg.num_labels).to(device)\n",
    "print(model.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62b394e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 10  MAML helpers\n",
    "# ============================\n",
    "\n",
    "def get_adaptable_weights(model: ACSCTransformer):\n",
    "    return OrderedDict({\n",
    "        \"W\": model.classifier.weight,\n",
    "        \"b\": model.classifier.bias,\n",
    "    })\n",
    "\n",
    "\n",
    "def forward_with_weights(model: ACSCTransformer, input_ids, attention_mask, fast_weights: OrderedDict):\n",
    "    out = model.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    cls = out.last_hidden_state[:, 0]\n",
    "    logits = F.linear(cls, fast_weights[\"W\"], fast_weights[\"b\"])\n",
    "    return logits\n",
    "\n",
    "\n",
    "def inner_adapt(model: ACSCTransformer, support_examples):\n",
    "    fast = get_adaptable_weights(model)\n",
    "\n",
    "    for _ in range(cfg.inner_steps):\n",
    "        input_ids, attn, y = encode_batch(support_examples)\n",
    "        logits = forward_with_weights(model, input_ids, attn, fast)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        grads = torch.autograd.grad(loss, list(fast.values()), create_graph=True)\n",
    "        fast = OrderedDict((k, v - cfg.inner_lr * g) for (k, v), g in zip(fast.items(), grads))\n",
    "\n",
    "    return fast\n",
    "\n",
    "\n",
    "def query_loss_and_acc(model: ACSCTransformer, fast_weights: OrderedDict, query_examples):\n",
    "    input_ids, attn, y = encode_batch(query_examples)\n",
    "    logits = forward_with_weights(model, input_ids, attn, fast_weights)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    preds = logits.argmax(dim=-1)\n",
    "    acc = (preds == y).float().mean().item()\n",
    "    return loss, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52eb1b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e90357c840b4ed9b2ad4d74510adab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/4:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: /content/drive/MyDrive/Capstone Project/outputs_maml/maml_acsc_epoch1.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90fe9d201af941fe8a498b69dbfbbb16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/4:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: /content/drive/MyDrive/Capstone Project/outputs_maml/maml_acsc_epoch2.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df49e9cf4bcd4e65be336fc52e8aec15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/4:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: /content/drive/MyDrive/Capstone Project/outputs_maml/maml_acsc_epoch3.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53caf596b5ff491c802935cb59b732c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/4:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint: /content/drive/MyDrive/Capstone Project/outputs_maml/maml_acsc_epoch4.pt\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 11  Train\n",
    "# ============================\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.meta_lr)\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in range(1, cfg.epochs + 1):\n",
    "    model.train()\n",
    "\n",
    "    pbar = tqdm(range(cfg.meta_iters_per_epoch), desc=f\"Epoch {epoch}/{cfg.epochs}\")\n",
    "    for it in pbar:\n",
    "        # sample tasks (aspects)\n",
    "        tasks = random.sample(train_aspects, k=min(cfg.tasks_per_meta_batch, len(train_aspects)))\n",
    "\n",
    "        meta_loss = 0.0\n",
    "        meta_acc = 0.0\n",
    "\n",
    "        for asp in tasks:\n",
    "            support, query = sample_episode(train_index, asp)\n",
    "            fast = inner_adapt(model, support)\n",
    "            qloss, qacc = query_loss_and_acc(model, fast, query)\n",
    "            meta_loss = meta_loss + qloss\n",
    "            meta_acc += qacc\n",
    "\n",
    "        meta_loss = meta_loss / max(1, len(tasks))\n",
    "        meta_acc = meta_acc / max(1, len(tasks))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        meta_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        history.append({\"epoch\": epoch, \"iter\": it, \"meta_loss\": float(meta_loss.item()), \"meta_acc\": float(meta_acc)})\n",
    "        pbar.set_postfix({\"loss\": f\"{meta_loss.item():.4f}\", \"acc\": f\"{meta_acc:.3f}\"})\n",
    "\n",
    "    # checkpoint per epoch\n",
    "    ckpt_path = os.path.join(cfg.ckpt_dir, f\"maml_acsc_epoch{epoch}.pt\")\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"cfg\": cfg.__dict__,\n",
    "        \"history\": history,\n",
    "    }, ckpt_path)\n",
    "    print(\"Saved checkpoint:\", ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a299e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     epoch  iter  meta_loss  meta_acc\n",
      "795      4   195   0.191687  0.916667\n",
      "796      4   196   0.241342  0.875000\n",
      "797      4   197   0.257371  0.875000\n",
      "798      4   198   0.285295  0.875000\n",
      "799      4   199   0.250658  0.875000\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 12  History view\n",
    "# ============================\n",
    "hist_df = pd.DataFrame(history)\n",
    "print(hist_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b2b3e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: /content/drive/MyDrive/Capstone Project/outputs_maml/maml_acsc_epoch4.pt\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 13  Load ckpt\n",
    "# ============================\n",
    "ckpt_to_eval = os.path.join(cfg.ckpt_dir, f\"maml_acsc_epoch{cfg.epochs}.pt\")\n",
    "ckpt = torch.load(ckpt_to_eval, map_location=device)\n",
    "model.load_state_dict(ckpt[\"model_state\"])\n",
    "model.eval()\n",
    "print(\"Loaded:\", ckpt_to_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9149941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60759300ee674a8fb084567038fe9cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval episodes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f0fa1c07ff4dff82811a284dc50df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Eval episodes:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episodic Test Results\n",
      "Mean loss: 0.7715268826391548\n",
      "Mean acc : 0.7191666878014803\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 14  Evaluate\n",
    "# ============================\n",
    "losses, accs = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in tqdm(range(cfg.eval_episodes), desc=\"Eval episodes\"):\n",
    "        asp = random.choice(test_aspects)\n",
    "        support, query = sample_episode(test_index, asp)\n",
    "\n",
    "        # Inner loop needs gradients, so temporarily enable grad\n",
    "        # We'll do it without no_grad for the adapt step.\n",
    "        \n",
    "# Re-run evaluation with gradients enabled for inner adaptation\n",
    "losses, accs = [], []\n",
    "\n",
    "for _ in tqdm(range(cfg.eval_episodes), desc=\"Eval episodes\"):\n",
    "    asp = random.choice(test_aspects)\n",
    "    support, query = sample_episode(test_index, asp)\n",
    "    fast = inner_adapt(model, support)\n",
    "    qloss, qacc = query_loss_and_acc(model, fast, query)\n",
    "    losses.append(float(qloss.item()))\n",
    "    accs.append(float(qacc))\n",
    "\n",
    "print(\"\\nEpisodic Test Results\")\n",
    "print(\"Mean loss:\", sum(losses) / len(losses))\n",
    "print(\"Mean acc :\", sum(accs) / len(accs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93857648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The battery lasts long but the charger is terrible.\n",
      "Aspect  : Battery\n",
      "Pred    : negative | conf: 0.616866946220398\n",
      "Probs   : [0.61686695 0.01721712 0.36591586]\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(sentence: str, aspect: str):\n",
    "    model.eval()\n",
    "    enc = tok(\n",
    "        [sentence],\n",
    "        [aspect],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=cfg.max_len,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    input_ids = enc[\"input_ids\"].to(device)\n",
    "    attn = enc[\"attention_mask\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attn)\n",
    "        probs = torch.softmax(logits, dim=-1)[0].detach().cpu().numpy()\n",
    "        pred = int(np.argmax(probs))\n",
    "    return cfg.id2label[pred], float(probs[pred]), probs\n",
    "\n",
    "\n",
    "demo_sentence = \"The battery lasts long but the charger is terrible.\"\n",
    "demo_aspect = \"Battery\"\n",
    "label, conf, probs = predict_sentiment(demo_sentence, demo_aspect)\n",
    "print(\"Sentence:\", demo_sentence)\n",
    "print(\"Aspect  :\", demo_aspect)\n",
    "print(\"Pred    :\", label, \"| conf:\", conf)\n",
    "print(\"Probs   :\", probs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
